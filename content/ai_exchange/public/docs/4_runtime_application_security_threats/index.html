<!doctype html><html lang=en><head><meta property="og:title" content="4. Runtime application security threats – AI Exchange"><meta property="og:description" content="Comprehensive guidance and alignment on how to protect AI against security threats - by professionals, for professionals."><meta property="og:type" content="article"><meta property="og:url" content="https://owaspai.org/docs/4_runtime_application_security_threats/"><meta property="og:image" content="https://owaspai.org/images/aix-og-logo.jpg"><meta property="article:section" content="docs"><meta charset=utf-8><script src=https://cdn.tailwindcss.com></script><meta name=viewport content="width=device-width,initial-scale=1"><title>4. Runtime application security threats | AI Exchange</title><meta name=description content><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap" rel=stylesheet><link rel=stylesheet href=/css/custom-style.css><script src=/js/script.js></script>
<link href=https://unpkg.com/aos@2.3.1/dist/aos.css rel=stylesheet><script src=https://unpkg.com/aos@2.3.1/dist/aos.js></script>
<script>AOS.init({delay:0,disable:"phone"})</script></head><body><header class=main-header><div class=header-background></div><div class="container header-container"><div class=logo-section><a href=/ class=logo-link><img src=/images/Owasp-AI-Exchange-Logo.png alt="AI Exchange" class=site-logo width=Auto height=48></a></div><nav class=main-navigation><ul class=nav-list><li class=nav-item><a href=/ class=nav-link>Home</a></li><li class=nav-item><a href=/docs/ai_security_overview/ class=nav-link>Overview</a></li><li class=nav-item><a href=/media/ class=nav-link>Media</a></li><li class=nav-item><a href=/contribute/ class=nav-link>Contribute</a></li><li class=nav-item><a href=/connect/ class=nav-link>Connect</a></li><li class=nav-item><a href=/sponsor/ class=nav-link>Sponsor</a></li></ul></nav><div class=header-actions><div class=social-icons><a href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide class=social-link title=GitHub><svg class="social-icon" viewBox="0 0 24 24" fill="currentcolor"><path d="M12 0C5.374.0.0 5.373.0 12c0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931.0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176.0.0 1.008-.322 3.301 1.23A11.509 11.509.0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221.0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/></svg></a><a href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide class=social-link title=Slack><svg class="social-icon" viewBox="0 0 24 24" fill="currentcolor"><path d="M5.042 15.165a2.528 2.528.0 01-2.52 2.523A2.528 2.528.0 010 15.165a2.527 2.527.0 012.522-2.52h2.52v2.52zm1.271.0a2.527 2.527.0 012.521-2.52 2.527 2.527.0 012.521 2.52v6.313A2.528 2.528.0 018.834 24a2.528 2.528.0 01-2.521-2.522v-6.313zM8.834 5.042a2.528 2.528.0 01-2.521-2.52A2.528 2.528.0 018.834.0a2.528 2.528.0 012.521 2.522v2.52H8.834zm0 1.271a2.528 2.528.0 012.521 2.521 2.528 2.528.0 01-2.521 2.521H2.522A2.528 2.528.0 010 8.834a2.528 2.528.0 012.522-2.521h6.312zM18.956 8.834a2.528 2.528.0 012.522-2.521A2.528 2.528.0 0124 8.834a2.528 2.528.0 01-2.522 2.521h-2.522V8.834zm-1.268.0a2.528 2.528.0 01-2.523 2.521 2.527 2.527.0 01-2.52-2.521V2.522A2.527 2.527.0 0115.165.0a2.528 2.528.0 012.523 2.522v6.312zM15.165 18.956a2.528 2.528.0 012.523 2.522A2.528 2.528.0 0115.165 24a2.527 2.527.0 01-2.52-2.522v-2.522h2.52zm0-1.268a2.527 2.527.0 01-2.52-2.523 2.526 2.526.0 012.52-2.52h6.313A2.527 2.527.0 0124 15.165a2.528 2.528.0 01-2.522 2.523h-6.313z"/></svg></a><a href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide class=social-link title=LinkedIn><svg class="social-icon" viewBox="0 0 24 24" fill="currentcolor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853.0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601.0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144.0-2.063-.926-2.063-2.065.0-1.138.92-2.063 2.063-2.063 1.14.0 2.064.925 2.064 2.063.0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225.0H1.771C.792.0.0.774.0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2.0 22.222.0h.003z"/></svg></a><a href=https://github.com/OWASP/www-project-ai-security-and-privacy-guide class=social-link title=Youtube><svg class="social-icon" viewBox="0 0 24 24" fill="currentcolor"><path d="M23.498 6.186A3.016 3.016.0 0021.376 4.05C19.505 3.545 12 3.545 12 3.545s-7.505.0-9.377.505A3.017 3.017.0 00.502 6.186C0 8.07.0 12 0 12s0 3.93.502 5.814a3.016 3.016.0 002.122 2.136c1.871.505 9.376.505 9.376.505s7.505.0 9.377-.505a3.015 3.015.0 002.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a></div><div class=search-icon><svg class="search-svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2"><circle cx="11" cy="11" r="8"/><path d="m21 21-4.35-4.35"/></svg></div></div></div></header><main id=main><section class="intro-banner text-white py-12 mb-0 bg-cover bg-center bg-no-repeat" style=background-image:url(/images/overview-hero.png)><div class="container text-left bg-opacity-50 p-8 rounded-lg"><h1 class="text-[46px] md:text-5xl font-bold mb-4">4. Runtime application security threats</h1><p class="text-lg text-gray-300">Engage with the OWASP AI team through various platforms.</p><button class="inline-block bg-[#4CAF50] hover:bg-emerald-700 text-white text-xl font-medium py-3 px-10 rounded-lg mt-[22px]">
Let's connect</button></div></section><div class=docs-layout><div class=docs-sidebar-column><aside class="docs-sidebar p-4"><div class=sidebar-container><nav class=sidebar-nav><ul class="flex flex-col"><li><a href=/docs/ai_security_overview/ class=sidebar-nav-link><span>0. AI Security Overview</span></a></li><li><a href=/docs/1_general_controls/ class=sidebar-nav-link><span>1. General controls</span></a></li><li><a href=/docs/2_threats_through_use/ class=sidebar-nav-link><span>2. Threats through use</span></a></li><li><a href=/docs/3_development_time_threats/ class=sidebar-nav-link><span>3. Development-time threats</span></a></li><li><a href=/docs/4_runtime_application_security_threats/ class="sidebar-nav-link active"><span>4. Runtime application security threats</span></a></li><li><a href=/docs/5_testing/ class=sidebar-nav-link><span>5. AI security testing</span></a></li><li><a href=/docs/6_privacy/ class=sidebar-nav-link><span>6. AI privacy</span></a></li><li><a href=/docs/ai_security_references/ class=sidebar-nav-link><span>AI Security References</span></a></li><li><a href=/docs/ class=sidebar-nav-link><span>Index</span></a></li></ul></nav></div></aside><div class=sidebar-more><h3 class=sidebar-title>More</h3><ul class="flex flex-col"><li><a href=/ class=sidebar-menu-item>Home</a></li><li><a href=/connect/ class=sidebar-menu-item>Connect with us</a></li><li><a href=/contribute/ class=sidebar-menu-item>Contribute</a></li><li><a href=/media/ class=sidebar-menu-item>Media</a></li><li><a href=/meetings/ class=sidebar-menu-item>Meetings</a></li><li><a href=https://forms.gle/XwEEK52y4iZQChuJ6 class=sidebar-menu-item>Register</a></li><li><a href=/sponsor/ class=sidebar-menu-item>Sponsor</a></li></ul></div></div><main class=docs-main><div class=docs-content><nav class=breadcrumbs><a href=/>Home</a>
<span class=breadcrumb-separator>></span>
<span class=current-page>4. Runtime application security threats</span></nav><h1 class=docs-title>4. Runtime application security threats</h1><div class=docs-body><blockquote><p>Category: group of runtime threats<br>Permalink: <a href=https://owaspai.org/goto/runtimeappsec/ target=_blank rel=noopener>https://owaspai.org/goto/runtimeappsec/</a></p></blockquote><h2>4.1. Non AI-specific application security threats<span class="absolute -mt-20" id=41-non-ai-specific-application-security-threats></span>
<a href=#41-non-ai-specific-application-security-threats class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: group of runtime threats<br>Permalink: <a href=https://owaspai.org/goto/generalappsecthreats/ target=_blank rel=noopener>https://owaspai.org/goto/generalappsecthreats/</a></p></blockquote><p>Impact: Conventional application security threats can impact confidentiality, integrity and availability of all assets.</p><p>AI systems are IT systems and therefore can have security weaknesses and vulnerabilities that are not AI-specific such as SQL-Injection. Such topics are covered in depth by many sources and are out of scope for this publication.<br>Note: some controls in this document are application security controls that are not AI-specific, but applied to AI-specific threats (e.g. monitoring to detect model attacks).</p><p><strong>Controls:</strong></p><ul><li>See the <a href=/goto/governancecontrols/>Governance controls</a> in the general section, in particular <a href=/goto/secdevprogram/>SECDEVPROGRAM</a> to attain application security, and <a href=/goto/secprogram/>SECPROGRAM</a> to attain information security in the organization.</li><li>Technical application security controls<br>Useful standards include:<ul><li>See <a href=https://www.opencre.org/cre/636-660 target=_blank rel=noopener>OpenCRE on technical application security controls</a></li><li>The ISO 27002 controls only partly cover technical application security controls, and on a high abstraction level</li><li>More detailed and comprehensive control overviews can be found in for example, Common criteria protection profiles (ISO/IEC 15408 with evaluation described in ISO 18045),</li><li>or in <a href=https://owasp.org/www-project-application-security-verification-standard/ target=_blank rel=noopener>OWASP ASVS</a></li></ul></li><li>Operational security<br>When models are hosted by third parties then security configuration of those services deserves special attention. Part of this configuration is <a href=/goto/modelaccesscontrol/>model access control</a>: an important mitigation for security risks. Cloud AI configuration options deserve scrutiny, like for example opting out when necessary of monitoring by the third party - which could increase the risk of exposing sensitive data.
Useful standards include:<ul><li>See <a href=https://www.opencre.org/cre/862-452 target=_blank rel=noopener>OpenCRE on operational security processes</a></li><li>The ISO 27002 controls only partly cover operational security controls, and on a high abstraction level</li></ul></li></ul><hr><h2>4.2. Runtime model poisoning (manipulating the model itself or its input/output logic)<span class="absolute -mt-20" id=42-runtime-model-poisoning-manipulating-the-model-itself-or-its-inputoutput-logic></span>
<a href=#42-runtime-model-poisoning-manipulating-the-model-itself-or-its-inputoutput-logic class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: runtime application security threat<br>Permalink: <a href=https://owaspai.org/goto/runtimemodelpoison/ target=_blank rel=noopener>https://owaspai.org/goto/runtimemodelpoison/</a></p></blockquote><p>Impact: see Broad model poisoning.</p><p>This threat involves manipulating the behavior of the model by altering the parameters within the live system itself. These parameters represent the regularities extracted during the training process for the model to use in its task, such as neural network weights. Alternatively, compromising the model&rsquo;s input or output logic can also change its behavior or deny its service.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#RUNTIMEMODELINTEGRITY<span class="absolute -mt-20" id=runtimemodelintegrity></span>
<a href=#runtimemodelintegrity class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/runtimemodelintegrity/ target=_blank rel=noopener>https://owaspai.org/goto/runtimemodelintegrity/</a></p></blockquote><p>Run-time model integrity: apply traditional application security controls to protect the storage of model parameters (e.g. access control, checksums, encryption) A Trusted Execution Environment can help to protect model integrity.</p><h4>#RUNTIMEMODELIOINTEGRITY<span class="absolute -mt-20" id=runtimemodeliointegrity></span>
<a href=#runtimemodeliointegrity class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/runtimemodeliointegrity/ target=_blank rel=noopener>https://owaspai.org/goto/runtimemodeliointegrity/</a></p></blockquote><p>Run-time model Input/Output integrity: apply traditional application security controls to protect the runtime manipulation of the model&rsquo;s input/output logic (e.g. protect against a man-in-the-middle attack)</p><hr><h2>4.3. Direct runtime model theft<span class="absolute -mt-20" id=43-direct-runtime-model-theft></span>
<a href=#43-direct-runtime-model-theft class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: runtime application security threat<br>Permalink: <a href=https://owaspai.org/goto/runtimemodeltheft/ target=_blank rel=noopener>https://owaspai.org/goto/runtimemodeltheft/</a></p></blockquote><p>Impact: Confidentiality breach of model parameters, which can result in intellectual model theft and/or allowing to perform model attacks on the stolen model that normally would be mitigated by rate limiting, access control, or detection mechanisms.</p><p>Stealing model parameters from a live system by breaking into it (e.g. by gaining access to executables, memory or other storage/transfer of parameter data in the production environment). This is different from <a href=/goto/modeltheftuse/>model theft through use</a> which goes through a number of steps to steal a model through normal use, hence the use of the word &lsquo;direct&rsquo;. It is also different from <a href=/goto/devmodelleak/>model theft development-time</a> from a lifecylce and attack surface perspective.</p><p>This category also includes <em>side-channel attacks</em>, where attackers do not necessarily steal the entire model but instead extract specific details about the model’s behaviour or internal state. By observing characteristics like response times, power consumption, or electromagnetic emissions during inference, attackers can infer sensitive information about the model. This type of attack can provide insights into the model&rsquo;s structure, the type of data it processes, or even specific parameter values, which may be leveraged for subsequent attacks or to replicate the model.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#RUNTIMEMODELCONFIDENTIALITY<span class="absolute -mt-20" id=runtimemodelconfidentiality></span>
<a href=#runtimemodelconfidentiality class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/runtimemodelconfidentiality/ target=_blank rel=noopener>https://owaspai.org/goto/runtimemodelconfidentiality/</a></p></blockquote><p>Run-time model confidentiality: see <a href=/goto/secdevprogram/>SECDEVPROGRAM</a> to attain application security, with the focus on protecting the storage of model parameters (e.g. access control, encryption).</p><p>A Trusted Execution Environment can be highly effective in safeguarding the runtime environment, isolating model operations from potential threats, including side-channel hardware attacks like <a href=https://sites.cs.ucsb.edu/~sherwood/pubs/ASPLOS-20-deepsniff.pdf target=_blank rel=noopener>DeepSniffer</a>. By ensuring that sensitive computations occur within this secure enclave,the TEE reduces the risk of attackers gaining useful information through side-channel methods.</p><p>Side-Channel Mitigation Techniques:</p><ul><li><p>Masking: Introducing random delays or noise during inference can help obscure the relationship between input data and the model’s response times, thereby complicating timing-based side-channel attacks. See <a href=https://www.iacr.org/archive/eurocrypt2013/78810139/78810139.pdf target=_blank rel=noopener>Masking against Side-Channel Attacks: A Formal Security Proof</a></p></li><li><p>Shielding: Employing hardware-based shielding could help prevent electromagnetic
or acoustic leakage that might be exploited for side-channel attacks. See <a href=https://ieeexplore.ieee.org/document/8015660 target=_blank rel=noopener>Electromagnetic Shielding for Side-Channel Attack Countermeasures</a></p></li></ul><h4>#MODELOBFUSCATION<span class="absolute -mt-20" id=modelobfuscation></span>
<a href=#modelobfuscation class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/modelobfuscation/ target=_blank rel=noopener>https://owaspai.org/goto/modelobfuscation/</a></p></blockquote><p>Model obfuscation: techniques to store the model in a complex and confusing way with minimal technical information, to make it more difficult for attackers to extract and understand a model after having gained access to its runtime storage. See this <a href=https://dl.acm.org/doi/abs/10.1145/3597926.3598113 target=_blank rel=noopener>article on ModelObfuscator</a></p><hr><h2>4.4. Insecure output handling<span class="absolute -mt-20" id=44-insecure-output-handling></span>
<a href=#44-insecure-output-handling class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: runtime application security threat<br>Permalink: <a href=https://owaspai.org/goto/insecureoutput/ target=_blank rel=noopener>https://owaspai.org/goto/insecureoutput/</a></p></blockquote><p>Impact: Textual model output may contain &rsquo;traditional&rsquo; injection attacks such as XSS-Cross site scripting, which can create a vulnerability when processed (e.g. shown on a website, execute a command).</p><p>This is like the standard output encoding issue, but the particularity is that the output of AI may include attacks such as XSS.</p><p>See <a href=https://genai.owasp.org/llmrisk/llm05/ target=_blank rel=noopener>OWASP for LLM 05</a>.</p><p><strong>Controls:</strong></p><ul><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#ENCODEMODELOUTPUT<span class="absolute -mt-20" id=encodemodeloutput></span>
<a href=#encodemodeloutput class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/encodemodeloutput/ target=_blank rel=noopener>https://owaspai.org/goto/encodemodeloutput/</a></p></blockquote><p>Encode model output: apply output encoding on model output if it text. See <a href=https://www.opencre.org/cre/161-451 target=_blank rel=noopener>OpenCRE on Output encoding and injection prevention</a></p><hr><h2>4.5. Leak sensitive input data<span class="absolute -mt-20" id=45-leak-sensitive-input-data></span>
<a href=#45-leak-sensitive-input-data class=subheading-anchor aria-label="Permalink for this section"></a></h2><blockquote><p>Category: runtime application security threat<br>Permalink: <a href=https://owaspai.org/goto/leakinput/ target=_blank rel=noopener>https://owaspai.org/goto/leakinput/</a></p></blockquote><p>Impact: Confidentiality breach of sensitive input data.</p><p>Input data can be sensitive (e.g. GenAI prompts) and can either leak through a failure or through an attack, such as a man-in-the-middle attack.</p><p>GenAI models mostly live in the cloud - often managed by an external party, which may increase the risk of leaking training data and leaking prompts. This issue is not limited to GenAI, but GenAI has 2 particular risks here: 1) model use involves user interaction through prompts, adding user data and corresponding privacy/sensitivity issues, and 2) GenAI model input (prompts) can contain rich context information with sensitive data (e.g. company secrets). The latter issue occurs with <em>in context learning</em> or <em>Retrieval Augmented Generation(RAG)</em> (adding background information to a prompt): for example data from all reports ever written at a consultancy firm. First of all, this context information will travel with the prompt to the cloud, and second: the context information may likely leak to the output, so it&rsquo;s important to apply the access rights of the user to the retrieval of the context. For example: if a user from department X asks a question to an LLM - it should not retrieve context that department X has no access to, because that information may leak in the output. Also see <a href=https://owaspai.org/docs/ai_security_overview/#how-to-select-relevant-threats-and-controls-risk-analysis target=_blank rel=noopener>Risk analysis</a> on the responsibility aspect.</p><p><strong>Controls:</strong></p><ul><li>See <a href=/goto/generalcontrols/>General controls</a>, in particular <a href=/goto/datalimit/>Minimizing data</a></li><li>The below control(s), each marked with a # and a short name in capitals</li></ul><h4>#MODELINPUTCONFIDENTIALITY<span class="absolute -mt-20" id=modelinputconfidentiality></span>
<a href=#modelinputconfidentiality class=subheading-anchor aria-label="Permalink for this section"></a></h4><blockquote><p>Category: runtime information security control against application security threats<br>Permalink: <a href=https://owaspai.org/goto/modelinputconfidentiality/ target=_blank rel=noopener>https://owaspai.org/goto/modelinputconfidentiality/</a></p></blockquote><p>Model input confidentiality: see <a href=/goto/secdevprogram/>SECDEVPROGRAM</a> to attain application security, with the focus on protecting the transport and storage of model input (e.g. access control, encryption, minimize retention)</p></div></div></main><aside class=docs-toc><div class=toc-container><h3 class=toc-title>On this page</h3><div class="toc-content bg-gradient-to-b from-[#CCF6CE] to-[#FDFBFB] border border-gray-300 rounded-lg p-4"><nav id=TableOfContents><ul><li><a href=#41-non-ai-specific-application-security-threats>4.1. Non AI-specific application security threats</a></li><li><a href=#42-runtime-model-poisoning-manipulating-the-model-itself-or-its-inputoutput-logic>4.2. Runtime model poisoning (manipulating the model itself or its input/output logic)</a><ul><li><ul><li><a href=#runtimemodelintegrity>#RUNTIMEMODELINTEGRITY</a></li><li><a href=#runtimemodeliointegrity>#RUNTIMEMODELIOINTEGRITY</a></li></ul></li></ul></li><li><a href=#43-direct-runtime-model-theft>4.3. Direct runtime model theft</a><ul><li><ul><li><a href=#runtimemodelconfidentiality>#RUNTIMEMODELCONFIDENTIALITY</a></li><li><a href=#modelobfuscation>#MODELOBFUSCATION</a></li></ul></li></ul></li><li><a href=#44-insecure-output-handling>4.4. Insecure output handling</a><ul><li><ul><li><a href=#encodemodeloutput>#ENCODEMODELOUTPUT</a></li></ul></li></ul></li><li><a href=#45-leak-sensitive-input-data>4.5. Leak sensitive input data</a><ul><li><ul><li><a href=#modelinputconfidentiality>#MODELINPUTCONFIDENTIALITY</a></li></ul></li></ul></li></ul></nav></div></div></aside></div><section class="relative bg-[#EDF7ED] py-16"><div class="max-w-[1400px] mx-auto px-6 md:px-12"><h2 class="text-3xl md:text-4xl font-bold text-center text-[#1a1a2e] mb-16">We are always happy to assist you!</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-12 items-start"><div><div class="flex flex-wrap gap-4 mb-8"><a href=# class="w-10 h-10 bg-white rounded-md flex items-center justify-center shadow"><i class="fab fa-github text-gray-700"></i></a>
<a href=# class="w-10 h-10 bg-white rounded-md flex items-center justify-center shadow"><i class="fab fa-youtube text-red-600"></i></a>
<a href=# class="w-10 h-10 bg-white rounded-md flex items-center justify-center shadow"><i class="fab fa-linkedin-in text-blue-700"></i></a>
<a href=# class="w-10 h-10 bg-white rounded-md flex items-center justify-center shadow"><img src=/images/slack.png alt=Slack class="w-6 h-6"></a></div><h3 class="text-2xl font-bold text-[#1a1a2e] mb-4">Send us a message</h3><p class="text-gray-500 leading-relaxed">Have questions about AI security? Want to contribute to our mission?
We'd love to hear from you. Reach out through any of our channels or
use the contact form.</p></div><div><form class="flex flex-col gap-6"><div class="grid grid-cols-1 md:grid-cols-2 gap-4"><input type=text placeholder="First Name*" class="p-4 border border-gray-300 rounded-lg text-base w-full">
<input type=text placeholder="Last Name*" class="p-4 border border-gray-300 rounded-lg text-base w-full"></div><input type=email placeholder="Email Address*" class="p-4 border border-gray-300 rounded-lg text-base w-full">
<textarea placeholder=Message rows=4 class="p-4 border border-gray-300 rounded-lg text-base resize-vertical w-full"></textarea>
<button type=submit class="bg-green-500 text-white px-6 py-3 rounded-lg font-bold flex items-center justify-center gap-2 w-max hover:bg-green-600 transition">
Submit <span>→</span></button></form></div></div></div></section></main><script src=https://cdn.tailwindcss.com></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css><link href="https://fonts.googleapis.com/css2?family=Inter:wght@500&family=Manrope:wght@600&family=Roboto:wght@500&display=swap" rel=stylesheet><script>tailwind.config={theme:{extend:{fontFamily:{inter:["Inter","sans-serif"],manrope:["Manrope","sans-serif"],roboto:["Roboto","sans-serif"]}}}}</script><footer class="bg-black text-white w-full py-6"><div class="container flex flex-col p-2 px-10"><div class="flex justify-between items-start"><div class="flex flex-col logo-section"><a href=/ class=logo-link><img src=/images/Owasp-AI-Exchange-Logo.png alt="OWASP AI Exchange" class="site-logo h-[39px] w-auto"></a><ul class="flex space-x-8 mt-4 font-roboto text-[16px]"><li><a href=/ class=hover:text-white>Home</a></li><li><a href=/docs/ai_security_overview/ class=hover:text-white>Overview</a></li><li><a href=/media/ class=hover:text-white>Media</a></li><li><a href=/sponsor/ class=hover:text-white>Sponsor</a></li><li><a href=/contribute/ class=hover:text-white>Contribute</a></li><li><a href=/connect/ class=hover:text-white>Connect</a></li></ul></div><div class="flex space-x-4 mt-10"><a href=# class="w-9 h-9 flex items-center justify-center border border-white rounded-full hover:bg-gray-800 transition"><i class="fab fa-github"></i></a>
<a href=# class="w-9 h-9 flex items-center justify-center border border-white rounded-full hover:bg-gray-800 transition"><i class="fab fa-slack"></i></a>
<a href=# class="w-9 h-9 flex items-center justify-center border border-white rounded-full hover:bg-gray-800 transition"><i class="fab fa-linkedin-in"></i></a>
<a href=# class="w-9 h-9 flex items-center justify-center border border-white rounded-full hover:bg-gray-800 transition"><i class="fab fa-youtube"></i></a></div></div><div class="border-t border-gray-600 mt-4"></div><div class="flex w-full flex-row justify-between space-between pt-6"><p class="font-roboto text-[16px]">Copyright © owasp.org 2025. All Rights Reserved.</p><p class="flex gap-2 text-[12px]">PROUDLY DESIGNED AND DEVELOPED BY:
<img src=/images/usability.png alt="Usability Icon" class="h-5 inline-block">
<a href=https://usabilitydesigns.com/ class=text-[#FFAE3C]>USABILITY DESIGNS</a></p></div></div></footer></body></html>