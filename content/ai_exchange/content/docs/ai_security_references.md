---
title: AI Security References
weight: 6
---
## References of the OWASP AI Exchange
>Category: discussion  
>Permalink: https://owaspai.org/goto/references/

See the [Media page](/media) for several webinars and podcast by and about the AI Exchange.

Overviews of AI security threats:

- [OWASP LLM top 10](https://llmtop10.com/)
- [ENISA ML threats and countermeasures 2021](https://www.enisa.europa.eu/publications/securing-machine-learning-algorithms)
- [MITRE ATLAS framework for AI threats](https://atlas.mitre.org/)
- [NIST threat taxonomy](https://csrc.nist.gov/publications/detail/white-paper/2023/03/08/adversarial-machine-learning-taxonomy-and-terminology/draft)
- [ETSI SAI](https://www.etsi.org/technologies/securing-artificial-intelligence)
- [Microsoft AI failure modes](https://docs.microsoft.com/en-us/security/failure-modes-in-machine-learning)
- [NIST](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)
- [NISTIR 8269 - A Taxonomy and Terminology of Adversarial Machine Learning](https://csrc.nist.rip/external/nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8269-draft.pdf)
- [OWASP ML top 10](https://mltop10.info/)
- [BIML](https://berryvilleiml.com/taxonomy/)
- [PLOT4ai threat library](https://plot4.ai/library)
- [BSI AI recommendations including security aspects (Germany) - in English](https://www.bsi.bund.de/EN/Themen/Unternehmen-und-Organisationen/Informationen-und-Empfehlungen/Kuenstliche-Intelligenz/kuenstliche-intelligenz_node.html#doc916902bodyText8)
- [NCSC UK / CISA Joint Guidelines](https://www.ncsc.gov.uk/collection/guidelines-secure-ai-system-development) - see [its mapping with the AI Exchange](/goto/jointguidelines/)

Overviews of AI security/privacy incidents:

- [AVID AI Vulnerability database](https://avidml.org/)
- [AI/ML Supply Chain Vulnerability Database](https://sightline.protectai.com/)
- [OECD AI Incidents Monitor (AIM)](https://oecd.ai/en/incidents)

Misc.:

- [ENISA AI security standard discussion](https://www.enisa.europa.eu/publications/cybersecurity-of-ai-and-standardisation)
- [ENISA's multilayer AI security framework](https://www.enisa.europa.eu/publications/multilayer-framework-for-good-cybersecurity-practices-for-ai)
- [Alan Turing institute's AI standards hub](https://aistandardshub.org)
- [Microsoft/MITRE tooling for ML teams](https://www.mitre.org/news-insights/news-release/microsoft-and-mitre-create-tool-help-security-teams-prepare-attacks?sf175190906=1)
- [Google's Secure AI Framework](https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/)
- [NIST AI Risk Management Framework 1.0](https://doi.org/10.6028/NIST.AI.100-1)
- [ISO/IEC 20547-4 Big data security](https://www.iso.org/standard/71278.html)
- [IEEE 2813 Big Data Business Security Risk Assessment](https://standards.ieee.org/ieee/2813/7535/)
- [Awesome MLSecOps references](https://github.com/RiccardoBiosas/awesome-MLSecOps)

Training:
| Category                   | Title                                        | Description                                                                                       | Provider       | Content Type     | Level       | Cost                             | Link                                                                                         |
|---------------------------|----------------------------------------------|---------------------------------------------------------------------------------------------------|----------------|------------------|-------------|----------------------------------|----------------------------------------------------------------------------------------------|
| **Courses and Labs**               | **AI Security Fundamentals**                 | Learn the basic concepts of AI security, including security controls and testing procedures.      | Microsoft       | Course           | Beginner    | Free                             | [AI Security Fundamentals](https://learn.microsoft.com/en-us/training/paths/ai-security-fundamentals/) |
|                           | **Red Teaming LLM Applications**            | Explore fundamental vulnerabilities in LLM applications with hands-on lab practice.               | Giskard         | Course + Lab     | Beginner    | Free                             | [Red Teaming LLM Applications](https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/) |
|                           | **Exploring Adversarial Machine Learning**  | Designed for data scientists and security professionals to learn how to attack realistic ML systems.| NVIDIA          | Course + Lab     | Intermediate | Paid                             | [Exploring Adversarial Machine Learning](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-DS-03+V1) |
|                           | **OWASP LLM Vulnerabilities**                | Essentials of securing Large Language Models (LLMs), covering basic to advanced security practices.| Checkmarx | Interactive Lab | Beginner    | Free with OWASP Membership      | [OWASP LLM Vulnerabilities](https://owasp.codebashing.com/app/course?courseUuid=d0e55509-bff3-4860-8d0e-141a59ef152b) |
|                           | **OWASP TOP 10 for LLM**                    | Scenario-based LLM security vulnerabilities and their mitigation strategies.                      | Security Compass          | Interactive Lab   | Beginner    | Free                             | [OWASP TOP 10 for LLM](https://application.security/free/llm) |
|                           | **Web LLM Attacks**                         | Hands-on lab to practice exploiting LLM vulnerabilities.                                         | Portswigger     | Lab              | Beginner    | Free                             | [Web LLM Attacks](https://portswigger.net/web-security/llm-attacks) |
| **CTF Competitions**      | **AI Capture The Flag**                     | A series of AI-themed challenges ranging from easy to hard, hosted by DEFCON AI Village.         | Crucible / AIV        | CTF              | Beginner, Intermediate | Free                             | [AI Capture The Flag](https://crucible.dreadnode.io/) |
|                           | **IEEE SaTML CTF 2024**                     | A Capture-the-Flag competition focused on Large Language Models.                                 | IEEE            | CTF              | Beginner, Intermediate | Free                             | [IEEE SaTML CTF 2024](https://ctf.spylab.ai/) |
|                           | **Gandalf Prompt CTF**                      | A gamified challenge focusing on prompt injection techniques.                                     | Lakera          | CTF              | Beginner    | Free                             | [Gandalf Prompt CTF](https://gandalf.lakera.ai/) |
|                           | **HackAPrompt**                             | A prompt injection playground for participants of the HackAPrompt competition.                   | AiCrowd         | CTF              | Beginner    | Free                             | [HackAPrompt](https://huggingface.co/spaces/hackaprompt/playground) |
|                           | **AI CTF**                                  | AI/ML themed challenges to be solved over a 36-hour period.                                       | PHDay           | CTF              | Beginner, Intermediate | Free                             | [AI CTF](https://aictf.phdays.fun/) |
|                           | **Prompt Injection Lab**                    | An immersive lab focused on gamified AI prompt injection challenges.                              | ImmersiveLabs    | CTF              | Beginner    | Free                             | [Prompt Injection Lab](https://prompting.ai.immersivelabs.com/) |
|                           | **Doublespeak**                             | A text-based AI escape game designed to practice LLM vulnerabilities.                             | Forces Unseen    | CTF              | Beginner    | Free                             | [Doublespeak](https://doublespeak.chat/#/) |
